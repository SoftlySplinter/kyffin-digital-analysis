\chapter{Background \& Objectives}

%This section should pick-up material from your progress report and enhance it based on the feedback and also your additional experience up to now. 

\section{Sir John ``Kyffin'' Williams}

Sir John ``Kyffin'' Williams (1918-2006) was a Welsh painter and printmaker, widely regarded as 
the defining artist of Wales during the 20\textsuperscript{th} century\cite{Davies2008Welsh}. He was advised to take up
art by a doctor after failing a British Army medical examination because of an `abnormality' 
(epilepsy) as something which would not tax his brain.

He studied at the Slade School of Fine Art and taught art in Highgate School, after which he 
retired to Anglesey until he died in 2006 after a long battle with cancer.

His most characteristic pictures are of Welsh landscapes, painted with thick layers of oil paint
applied with a palette knife\cite{Chilvers2009Dictionary}. Most of his paintings are highly textural; to the point of being
3-dimensional.

As his life progressed Kyffin's `abnormality' grew steadily worse, especially when exposed to 
bright light. As a result most of his paintings are of overcast Welsh landscapes and tend to 
become visibly darker over time\cite{Harris2011How}. By eye it is generally quite easy to approximate the time period
in which a painting was created.

In 1969 he won a scholarship to study and paint in Y Wladfa; the Welsh settlement in Patagonia.
This period of his life is very obvious from his paintings as there is a complete contrast in 
colour between Patagonian and Welsh landscapes.


\section{Interdisciplinary work with the National Library of Wales}

% FIXME Llyod's Thesis Title
This project was initially suggested through a conversation between Hannah Dee and Gareth ``Llyod''
Roderick about image processing and art. Llyod is a PhD student at the \gls{nlw}.
Their initial idea was to try to geolocate a Kyffin painting on a map to build up a geographical 
representation of Kyffin's work.

Hannah started to create a prototype for performing geographical analysis, this proved to be a 
difficult task and one which is still being researched.

However, the nature of Kyffin's illness and painting style allows for a second form of analysis:
temporal. As previously stated it is fairly easy to judge by eye a good approximation of the 
period in which a Kyffin painting was created. It should, therefore, follow that this process can
be performed digitally.

When I started this project I was given a ``database'' (in reality this was just a spreadsheet) 
Llyod had produced, containing information of Kyffin Williams' paintings, including: title, year,
category (landscape, portrait, etc.), canvas size and a few additional details which aren't so 
relevant to the project.

The first meeting held was between Llyod, Hannah and I, in which we discussed the current state of
the project, what our aims for the project were and what form of help Llyod could provide to us.
As one of the objectives of this project is to, eventually, get a paper published, the relevant
details of the process we would need to go through if we wanted to do so.

The second meeting was between Hannah, Llyod, Lorna M. Hughes (Llyod's supervisor) and I. Again we
discussed the state of the project. Llyod had also produced a better version of his ``database'' 
to be more machine readable and succinct. A lot of information came from this meeting;

\begin{itemize}
\item The ``cut-off'' point between early and late is around 1973.
\item The size of the canvas might be a useful data point to use in classification, as Kyffin sold
more paintings he would have had the money available for larger canvases and the paint for said
canvas.
\item It is a little dubious as to whether some dates can be trusted. One painting owned by the
NLW was stated to be his last painting, but Lorna believes it was painted much earlier and claimed
to be his last to improve the sale price.
\item Llyod may have found date markings on some paintings. These again may not be accurate, but
may prove to increase the sample size.
\item It should be easy to provide a ``no later than'' estimate for each painting from the art
historians.
\item Paul (?) should be able to produce some exemplars for us as a ground truth.
\item Llyod may be able to find more paintings in the hands of private collectors to increase the 
sample size.
\item Llyod had been playing around with ImageJ to do some basic graph plotting. This might be 
useful to look at further to expand my own work.
\end{itemize}

There were also more detailed discussions about publications, particularly in a digital humanities
journal.


\subsection{Continuation of the Kyffin Project}

There are several projects that could continue on from the Kyffin Project.

One was to use the Learning/Teaching development fund to produce a web-based front-end for of some
of my analysis.

Another venture was to look into PhD funding to build up a 3D map of some of Kyffin's paintings
and being able to display it (perhaps via HTML5 and WebGL) so they can explore the painting 
digitally how it is meant to be in real life.



\section{Existing Work}

\subsection{Edge-Orientated Gradients}\label{sec:existing-hogs}
As Kyffin Williams' work is highly texturally, looking at the edge orientation of the image is
likely to be a valuable technique to use.

One technique recommended by Hannah was to look at \gls{hog}. The suggested paper outlined the use
of grids of \gls{hog} descriptors to improve the feature set for robust visual object
recognition\cite{Dalal2005Histograms}. As it significantly improves the feature set it seems
sensible to try and implement it as a technique without the Kyffin project to experiment with a
non colour-based approach.

The approach involves quite a few separate steps, only some of which are relevant to the project:

\begin{enumerate}
\item Gamma and colour normalization. Grayscale, \gls{rgb} and \gls{lab} spaces were used.
\gls{rgb} and \gls{lab} give similar results. Grayscale reduced performance less that square root 
gamma compression, but not as much as log compression.

\item Compute gradients. Often the simplest are the better here; Gaussian smoothing followed by 
discrete derivative masks (e.g.: figure~\ref{fig:1x2-ddm}, figure~\ref{fig:1x3-ddm}), etc. For 
colour this was done for each channel, and take the one with the largest norm.

\item Spatial and Orientation binning:
\begin{itemize}
\item Spatial binning is done by splitting the images into cells which can be rectangle or radial.
\item Orientation binning are spaced equally between either 0-180 "unsigned" or 0-360 "signed" 
bins.
\end{itemize}

\item Normalisation and Descriptor Blocks. Gradients vary over foreground/background, etc. 
Typically the blocks were overlapped so that each scalar response contains several components.

\item Pass a detector window across the image.

\item Run through a Linear \gls{svm} to classify the image.
\end{enumerate}

\begin{figure}[h]
$$
\begin{bmatrix}
-1 \\
1
\end{bmatrix}
$$
\caption{Example of a 1 by 2 Discrete Derivative Mask} \label{fig:1x2-ddm}
\end{figure}

\begin{figure}[h]
$$
\begin{bmatrix}
-1 \\
0 \\
1
\end{bmatrix}
$$
\caption{Example of a 1 by 3 Discrete Derivative Mask} \label{fig:1x3-ddm}
\end{figure}

Obviously, when applying this as an analysis technique to paintings, there are some points which
are completely irrelevant. Passing a detector window and running through a Linear \gls{svm} are
the obvious two. Normalisation is another unneeded step; computing performance isn't likely to be
a large issue for this project; so long as the techniques complete within a semi-reasonable amount
of time.

The leaves the act of computing the gradients (again, this can be done without Gaussian smoothing
as that reduces accuracy) which should a simple matter implemented by earlier techniques. Binning 
by \gls{rhog} or \gls{chog} descriptors, which may prove to the one of the more difficult parts of
implementing this technique.

\Gls{rhog} descriptors have similarities to \gls{sift} descriptors, but are used quite 
differently; \gls{sift} descriptors are optimised for sparse baseline matching whilst \gls{rhog}
descriptors are optimised for the dense and robust coding of a spatial form. The size of the
descriptor affects performance when using \gls{rhog}, for paintings it may turn out that a size
relating to the original size of the painting is a good way of getting around this problem.

\Gls{chog} descriptors become more complex still. They are similar to Shape 
Context\cite{ Belongie2001Matching}, but differ in one key aspect: in \gls{chog} descriptors each
spatial cell holds a stack of gradient-weighted orientation cells over an orientation-independent
edge-presence count which Shape Contexts use.

According to the author it is better to think of \gls{chog} descriptors as an advanced form of 
centre-surround coding as small descriptors with very few radial bins gave the best results.

Local contrast normalisation can be performed to help against local variations in the illumination
of foreground and background.

It would seem that both \gls{rhog} and \gls{chog} descriptors are designed more for the detection
window rather than analysis technique. This may make them less useful and result in an implemented
technique being just a simple histogram of edge orientations.

\subsection{Brush-stroke Analysis}\label{sec:existing-brush-stroke}
Stroke analysis is one of the main goals for this project. It is quite apparent from looking at 
Kyffin Williams' paintings that his brush-strokes change over time, his early work having lots of
smaller strokes over the canvas to large bold strokes in his later work.

The first paper I found relating to the analysis of brush-strokes involved moving a circular filter
across the whole painting to find the ridges of strokes, then filling any unbroken areas. They then
shrunk these areas to a single pixel line and fitted a $n^{\text{th}}$ order polynomial to this
line\cite{Berezhnoy2005Authentic}. This method seems fairly simplistic, but could be an interesting
first step, but as it is more focused on authenticating paintings it may be of limited use.

Another method for stroke analysis has been published in the IEEE Transactions on Pattern Analysis
and Machine Learning journal. This method is far more complex, but is able to extract and label
individual brush-strokes. An interesting part of their findings was the ability to date some of Van
Gogh's paintings to a known period in his career\cite{Li2012Rhythmic}.

This method involves performing edge detection of the painting followed by an edge linking 
algorithm which aims to remove small, noisy edges and to trace every edge. With this they then
perform enclosing, as strokes may not be complete this stage also aims to fill in missing gaps of
strokes and to fill these in within a certain tolerance.

The algorithm then decides if a stroke really is a painted stroke, if the stroke is completely 
enclosed, isolated from other non-edge pixels and forms a connected component then it is likely 
that it is a proper brush-stroke and is extracted. The edge pixels are used as the background and
the non-edge pixels as the foreground, this is the process of labelling the brush-stroke.

For each of these labelled candidates, a heuristic function is used to threshold any brush-strokes 
that are either too long or too short, these strokes are discarded. These strokes are then
considered to be candidates if they are not significantly branched, the stroke is not too wide 
(this may change for Kyffin Williams as he used a pallet knife rather than a brush) and the 
brush-stroke is not too big or small.

Separately, the image is then segmented using $k$-means clustering by \gls{rgb} values. This clustering 
algorithm is applied several times, lowering the tolerances for distance within a cluster. 
Connected components as a result of this clustering and have noise reduction performed upon them.
Finally, the two types of brush-strokes are combined.

This technique may need some changing to account for Kyffin Williams' use of a pallet knife, but
the overall principals of this technique should work with Kyffin's paintings.


\section{Analysis Objectives}
Analysis is one of the biggest sections of this project and involves creating techniques which 
will allow comparison of paintings in a way which will allow some form of classification to be
performed on them.

Typically I would expect this to produce some form of high-dimension state space in which each
painting is a point in the state space. From this state space the distance between one painting
and another can be easily resolved using a distance measure like Manhattan distance 
\eqref{eq:manhattan_distance}, euclidean distance \eqref{eq:euclidean_distance} or a distance 
measure more specific to the state space should it be needed (e.g.: chi-squared for histograms).

\begin{equation}\label{eq:manhattan_distance}
d_1(\mathbf{p},\mathbf{q}) = \|\mathbf{p}-\mathbf{q}\|_1 = \sum^{n}_{i=0}{|p_i-q_i|}
\end{equation}

\begin{equation}\label{eq:euclidean_distance}
d_1(\mathbf{p}, \mathbf{q}) = \sqrt{\sum^{n}_{i=0}({q_i-p_i})^2}
\end{equation}

\subsection{Colour-space Analysis}
The simplest way of analysing a digital image is to look at the colours which it consists of.
Doing this is relatively simple; each pixel has a set of values defining the colour of that point,
getting something meaningful from this is less simple.

The simplest strategy is to perform some form of statistical analysis on each painting then use
this for classification. Several good and computationally cheap options exist for this; 
mean \eqref{eq:mean} and standard deviation \eqref{eq:std_dev}, are some good
examples which often come predefined in image processing and computer vision libraries.

\begin{equation}\label{eq:mean}
\upmu = \frac{1}{N}\sum_{i=1}^{N}x_i
\end{equation}

\begin{equation}\label{eq:std_dev}
\sigma = \sqrt{\frac{1}{N}\sum_{i=1}^{N}(x_i - \upmu)^2}
\end{equation}

The representation of colour is another important factor, an \gls{rgb} representation will have all 
three values change if there are many changes in brightness of the colours whilst a \gls{hsv} 
representation will only have a single value change.

Therefore, an object of this section should be to explore different colour models and statistical
methods which can be applied to them.

Another useful technique which should be investigated early into the project are image histograms.
These histograms plot the distribution of colour across an image and are therefore a very powerful
method of analysing an image, especially for comparison. As with statistical analysis, histograms
will be largely effective by colour model.

\subsection{Texture Analysis}
As Kyffin Williams' work is very textural, it follows that a main part of the analysis should
focus around the texture of his paintings. Unfortunately for this section, it seems unlikely that
I will be able to get any 3-dimensional models of Kyffin's paintings. This would have been a nice,
if rather large, section of the project.

Instead it is more sensible to look at the orientation of edges in Kyffin's work. Some useful 
pre-existing techniques have already been discussed in section~\ref{sec:existing-hogs}. Histograms
of edge orientation\cite{Dalal2005Histograms} seem like a promising concept which may prove 
relatively simple to implement.

This section may also help with any work into brush-stroke analysis (see 
section~\ref{sec:analysis-brush-stroke}).

\subsection{Brush-stroke Analysis}\label{sec:analysis-brush-stroke}
With Kyffin's distinctive style and how obviously this style changes over time, the ultimate aim 
of this project is to be able to analyse the brush-strokes\footnote{A slight misnomer as Kyffin 
used a palette knife to paint with rather than a traditional brush} in a painting.

From looking at the paintings it is very apparent that in his earlier work he made a lot more 
strokes than in his later works\footnote{Although this isn't quite true as the canvases he worked
on in his later life tended to be larger}. The strokes in his later work tend to have larger areas
and span more of the canvas.

If it is possible to calculate a rough amount and size of strokes made in a given painting it 
should be a reasonable piece of data to classify on. As previously discussed in section~
\ref{sec:existing-brush-stroke} there has already been a decent amount of research into determining
brush-strokes in a painting. 

It would be preferable to try and take one of the techniques discussed in that research and change
it to suit the needs of the project rather than attempting to create a whole new method of 
brush-stroke recognition.

\subsection{Ensemble Techniques}
With some of the aforementioned analysis techniques it makes sense to combine two or more 
techniques together; a good example would be colour histograms and histograms of edge orientation.

This form of analysis is inspired by the concept of the same name in statistics and machine 
learning which tend to obtain better predictive performance. It may also be worth while trying to
weight different techniques so that the techniques which give the best performance affect the 
result of the ensemble technique more.


\section{Classification Objectives}
The overall objective of classification is to be able to label a painting by Kyffin Williams as 
being painted in a given year based on analysis performed on all other paintings with known years.

This ties in with the main aim of this project of being able to classify any Kyffin Williams
painting, whether it has a known or unknown year, as being from a given year. Evidently for 
paintings with an unknown year it is difficult to know how accurately the system has been, so, for
the most part, these paintings have been ignored and those paintings with a known year have made
up the training and validation set.

Because of the small size of paintings with known years it should be computationally viable to 
perform leave-one-out cross validation (figure~\ref{fig:loocv}).

\begin{figure}[h]
\begin{algorithmic}
\Function{LOOCV}{$data$} \Comment{$data$ is a set of all data points}
  \ForAll{$item \in data$}
    \State $classified_{item} \gets$ \Call{Classify}{$item, data \setminus \left\{{item}\right\}$} 
  \EndFor
  \Statex
  \Return $classified$
\EndFunction
\end{algorithmic}
\caption{Pseudocode for Leave-One-Out Cross Validation}\label{fig:loocv}
\end{figure}

This can be used to evaluate the performance of the analysis technique and classification 
algorithm. Pearson's product-moment correlation coefficient \eqref{eq:pearsons} between actual year
and classified year has been suggested to be a good performance measure for this project.

\begin{equation}\label{eq:pearsons}
\rho_{X,Y}={\mathrm{cov}(X,Y) \over \sigma_X \sigma_Y} ={E[(X-\mu_X)(Y-\mu_Y)] \over \sigma_X\sigma_Y}
\end{equation}


\subsection{Classification}
One of the simplest methods of classification is $k$-Nearest Neighbour (figure~\ref{fig:knn}) from
this one can take a poll of the years for each neighbour and assign the year of the painting to
classify to be the average of these years.

Depending which form of average you take (mathematical mean \eqref{eq:mean}, median or mode) will
alter the result; although it should be noted that median is very unlikely to give a result on its
own due to the sparseness of the data.

\begin{figure}[h]
\begin{algorithmic}
\Require{$0 < k \leq \left|{data}\right|$} \Comment{$data$ is a set of all data points}
\Function{KNearestNeighbour}{$k, data$}
  \For{$i = 1 \to k$}
    \State $nn_i \gets \Call{Nearest}{data}$
    \State $data \gets data \setminus \left\{{nn_i}\right\}$
    \State $i = i + 1$
  \EndFor
  \Statex
  \Return $nn$
\EndFunction
\end{algorithmic}
\caption{Pseudocode for $k$-Nearest Neighbour}\label{fig:knn}
\end{figure}

There are other techniques which could be applied to this problem, but the rewards for 
implementing them is not likely to be outweighed by the time it would take to implement such
techniques. There is a workaround for this; there are several machine learning tool-kits which 
provide pre-implemented version of these techniques.

One of the most popular tool-kits available for general use is Weka\cite{Hall2009WEKA}, which is discussed in more
detail in section~\ref{sec:bg-weka}.

% FIXME Find out who Julie is here.
Another technique suggested by Julie Greensmith is to use \gls{lcs}\cite{Bacardit2013Largescale}, 
which has an implementation for Weka. This may prove to give very good results for the kind of
analysis being performed on Kyffin's work.

\subsubsection{Use of Weka}\label{sec:bg-weka}

%\subsubsection{Learning Classifier Systems (LCS)}

\subsection{Exemplars}
The use of exemplar images would be another way of performing classification. The idea of an 
exemplar is that a painting is the most representative of a given time period. With the help of
Llyod, Lorna and the \gls{nlw} a list of exemplars which can be used as a ground truth to classify
against has been produced.

The initial idea for digitally producing exemplars is to take the middle painting for a time 
period, as would be expected. These can then be compared to the ground truths to see how correct
the analysis technique performed.

However, there is also the potentially to generate a theoretical exemplar from the analysis. This
might be hard to perform validation against the ground truth upon, but will give some useful data
on Kyffin Williams' style and how it changed.

These theoretical exemplars would likely be produced using some form of Gaussian mixture model.
